# /devops/logging/elk/pipeline.conf

input {
  tcp {
    port => 5044
    codec => json_lines
    ssl_enable => true
    ssl_cert => "/etc/logstash/certs/logstash.crt"
    ssl_key => "/etc/logstash/certs/logstash.key"
    ssl_verify => false
  }
  udp {
    port => 514
    type => "syslog"
  }
  beats {
    port => 5045
    ssl => true
    ssl_certificate => "/etc/logstash/certs/logstash.crt"
    ssl_key => "/etc/logstash/certs/logstash.key"
  }
}

filter {
  if [type] == "syslog" {
    grok {
      match => { "message" => "%{SYSLOGLINE}" }
    }
    date {
      match => [ "timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ]
    }
  }

  if [log_type] == "nginx_access" {
    grok {
      match => { "message" => "%{COMBINEDAPACHELOG}" }
    }
    geoip {
      source => "clientip"
    }
  }

  mutate {
    remove_field => [ "host", "input", "agent", "@version" ]
  }

  if "_grokparsefailure" in [tags] {
    drop { }
  }

  # Удаление потенциально чувствительных данных
  mutate {
    gsub => [
      "message", "(?i)apikey=[a-z0-9]{32,}", "apikey=[FILTERED]",
      "message", "(?i)token=[a-z0-9\-._]+", "token=[FILTERED]",
      "message", "(?i)password=[^&\s]+", "password=[FILTERED]"
    ]
  }
}

output {
  elasticsearch {
    hosts => ["https://elasticsearch.internal:9200"]
    index => "logs-%{+YYYY.MM.dd}"
    user => "${ELASTIC_USERNAME}"
    password => "${ELASTIC_PASSWORD}"
    ssl => true
    cacert => "/etc/logstash/certs/ca.crt"
  }

  if "_grokparsefailure" in [tags] {
    file {
      path => "/var/log/logstash/parse_errors.log"
      codec => line { format => "Failed parsing: %{message}" }
    }
  }

  stdout { codec => rubydebug { metadata => false }
