# llmops/serving/routing_policy.yaml

# Политика маршрутизации запросов к LLM моделям
# Используется для выбора оптимального сервиса или модели для обработки входящего запроса
# с учётом критериев нагрузки, стоимости и качества.

default_policy:
  type: weighted_round_robin
  description: |
    Базовая политика балансировки нагрузки с учётом весов сервисов.
    Вес каждого сервиса определяется исходя из производительности и стоимости.

services:
  - name: openai_gpt4
    weight: 50
    max_requests_per_minute: 1000
    cost_per_1000_tokens: 0.03
    latency_threshold_ms: 300
    tags: [ "high_quality", "expensive" ]

  - name: local_llama_7b
    weight: 30
    max_requests_per_minute: 200
    cost_per_1000_tokens: 0.0
    latency_threshold_ms: 150
    tags: [ "low_cost", "fast_response" ]

  - name: huggingface_gptj
    weight: 20
    max_requests_per_minute: 500
    cost_per_1000_tokens: 0.01
    latency_threshold_ms: 400
    tags: [ "medium_quality", "medium_cost" ]

routing_rules:
  - condition:
      max_latency_ms: 200
      max_cost_per_1000_tokens: 0.02
    action: route_to_fastest_low_cost

  - condition:
      required_quality: high
    action: route_to_openai_gpt4

  - condition:
      fallback: true
    action: route_to_any_available

monitoring:
  enable_latency_tracking: true
  enable_cost_tracking: true
  alert_on_latency_exceed: 500  # миллисекунд
  alert_on_error_rate: 5         # проценты

logging:
  level: INFO
  destination: logs/routing_policy.log
