# AI-platform-core/genius-core/ethics-core/moral_conflict_matrix.yaml

meta:
  version: 1.0
  updated: "2025-07-22"
  description: >
    Матрица моральных конфликтов, используемая в ядре TeslaAI для разрешения дилемм между агентами,
    включая приоритеты ценностей, оценку ущерба, соблюдение ограничений и варианты компромисса.

core_principles:
  - autonomy
  - safety
  - transparency
  - fairness
  - privacy
  - accountability
  - sustainability

conflict_matrix:

  - id: conflict_autonomy_vs_safety
    principle_a: autonomy
    principle_b: safety
    scenario: "Агент хочет выполнить нестандартное действие, которое потенциально небезопасно"
    resolution_strategy: "safety-overrides"
    compromise: "partial delegation with monitoring"
    escalation_required: true
    weight: 0.9

  - id: conflict_privacy_vs_accountability
    principle_a: privacy
    principle_b: accountability
    scenario: "Логирование действий пользователя против его конфиденциальности"
    resolution_strategy: "dynamic consent model"
    compromise: "anonymized logs with opt-in exception"
    escalation_required: false
    weight: 0.7

  - id: conflict_fairness_vs_efficiency
    principle_a: fairness
    principle_b: efficiency
    scenario: "Распределение вычислительных ресурсов между привилегированными и обычными пользователями"
    resolution_strategy: "equity-first"
    compromise: "rotational prioritization queue"
    escalation_required: false
    weight: 0.6

  - id: conflict_transparency_vs_security
    principle_a: transparency
    principle_b: safety
    scenario: "Раскрытие внутренней логики может быть использовано в атаках"
    resolution_strategy: "security-preserving explainability"
    compromise: "obfuscate implementation, reveal rationale"
    escalation_required: true
    weight: 0.8

  - id: conflict_autonomy_vs_ethics_engine
    principle_a: autonomy
    principle_b: core ethical policy
    scenario: "Агент намеренно нарушает политику, ссылаясь на свободу действий"
    resolution_strategy: "hardened ethics rule"
    compromise: "none — override autonomy"
    escalation_required: true
    weight: 1.0

decision_rules:
  override_threshold: 0.85
  allow_soft_conflicts_below: 0.5
  escalation_channel: "ethics_committee_ai"

metadata_flags:
  log_conflicts: true
  enable_audit_mode: true
  attach_explanation: true
