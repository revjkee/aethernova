{
  "id": null,
  "uid": "llm-latency",
  "title": "LLM Latency Dashboard",
  "tags": ["llmops", "latency", "performance", "sla"],
  "timezone": "browser",
  "schemaVersion": 39,
  "version": 1,
  "refresh": "15s",
  "panels": [
    {
      "type": "timeseries",
      "title": "Total Response Latency (P95)",
      "id": 1,
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "histogram_quantile(0.95, sum(rate(llm_response_latency_seconds_bucket[5m])) by (le))",
          "refId": "A"
        }
      ]
    },
    {
      "type": "timeseries",
      "title": "Inference Latency (P50 / P95 / P99)",
      "id": 2,
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "histogram_quantile(0.50, sum(rate(llm_inference_latency_seconds_bucket[5m])) by (le))",
          "refId": "A",
          "legendFormat": "P50"
        },
        {
          "expr": "histogram_quantile(0.95, sum(rate(llm_inference_latency_seconds_bucket[5m])) by (le))",
          "refId": "B",
          "legendFormat": "P95"
        },
        {
          "expr": "histogram_quantile(0.99, sum(rate(llm_inference_latency_seconds_bucket[5m])) by (le))",
          "refId": "C",
          "legendFormat": "P99"
        }
      ]
    },
    {
      "type": "timeseries",
      "title": "Tokenization Latency",
      "id": 3,
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "avg_over_time(llm_tokenization_latency_seconds[5m])",
          "refId": "A"
        }
      ]
    },
    {
      "type": "timeseries",
      "title": "Prompt Preprocessing Latency",
      "id": 4,
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "avg_over_time(llm_prompt_preprocess_latency_seconds[5m])",
          "refId": "A"
        }
      ]
    },
    {
      "type": "stat",
      "title": "Timeout Rate",
      "id": 5,
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "rate(llm_request_timeout_total[5m])",
          "refId": "A"
        }
      ]
    },
    {
      "type": "timeseries",
      "title": "API Gateway Latency (P95)",
      "id": 6,
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "histogram_quantile(0.95, sum(rate(api_gateway_latency_seconds_bucket[5m])) by (le))",
          "refId": "A"
        }
      ]
    },
    {
      "type": "heatmap",
      "title": "Latency Distribution (Inference)",
      "id": 7,
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "rate(llm_inference_latency_seconds_bucket[1m])",
          "refId": "A"
        }
      ]
    },
    {
      "type": "table",
      "title": "Top Slowest Endpoints",
      "id": 8,
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "topk(5, avg_over_time(llm_endpoint_latency_seconds[5m]))",
          "refId": "A"
        }
      ]
    },
    {
      "type": "stat",
      "title": "Avg Model Load Time",
      "id": 9,
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "avg_over_time(llm_model_load_latency_seconds[10m])",
          "refId": "A"
        }
      ]
    },
    {
      "type": "timeseries",
      "title": "Output Filter Latency",
      "id": 10,
      "datasource": "Prometheus",
      "targets": [
        {
          "expr": "avg_over_time(llm_output_filter_latency_seconds[5m])",
          "refId": "A"
        }
      ]
    }
  ]
}
