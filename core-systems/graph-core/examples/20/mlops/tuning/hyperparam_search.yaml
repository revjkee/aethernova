# Промышленный конфиг для гиперпараметрического поиска
# Совместим с: Optuna, Ray Tune, Keras Tuner, scikit-optimize, Ax, BOHB

search_strategy: "bayesian"  # grid | random | bayesian | hyperband | optuna | evolutionary

max_trials: 100
max_concurrent: 4
early_stopping:
  enabled: true
  metric: "val_loss"
  mode: "min"
  patience: 5
  threshold: 0.001

parameters:

  learning_rate:
    type: float
    distribution: loguniform
    min: 1e-5
    max: 1e-1

  batch_size:
    type: int
    distribution: categorical
    values: [16, 32, 64, 128]

  dropout:
    type: float
    distribution: uniform
    min: 0.0
    max: 0.7

  optimizer:
    type: categorical
    values: ["adam", "sgd", "rmsprop", "adamw"]

  activation:
    type: categorical
    values: ["relu", "gelu", "elu", "silu"]

  num_layers:
    type: int
    distribution: uniform
    min: 2
    max: 12

  hidden_dim:
    type: int
    distribution: step
    min: 64
    max: 1024
    step: 64

  weight_decay:
    type: float
    distribution: loguniform
    min: 0.00001
    max: 0.01

  gradient_clip:
    type: float
    distribution: uniform
    min: 0.0
    max: 1.0

  scheduler:
    type: categorical
    values: ["none", "linear", "cosine", "step"]

  warmup_ratio:
    type: float
    distribution: uniform
    min: 0.0
    max: 0.2

  seed:
    type: int
    distribution: categorical
    values: [42, 1337, 2023, 777, 888]

metadata:
  created_by: "TeslaAI Genesis AutoML v7"
  format_version: "1.0.0"
  tags: ["automated", "secure", "multi-framework"]
  compatible_tools:
    - optuna
    - ray-tune
    - keras-tuner
    - wandb sweep
    - skopt
    - ax
